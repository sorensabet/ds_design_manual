{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-19: How to efficiently scrape web data \n",
    "\n",
    "1. Check Terms of Service for each website to see if they allow web-scraping \n",
    "2. Be respectful of the website, space out scraping calls in reasonable intervals \n",
    "3. Have functionality to scrape specific parts of the website based on changes rather than scraping the whole thing each time\n",
    "\n",
    "4. Check for API's/open source crawlers for popular websites \n",
    "5. Write a crawler using open-source web scraping libraries \n",
    "6. Look for specific html tags that identify the part of the website we specifically want\n",
    "7. Hire an external agency to scrape the data for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
